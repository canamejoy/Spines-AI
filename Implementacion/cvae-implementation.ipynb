{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2378330,"sourceType":"datasetVersion","datasetId":492658},{"sourceId":12018245,"sourceType":"datasetVersion","datasetId":7561200},{"sourceId":13796176,"sourceType":"datasetVersion","datasetId":8783630},{"sourceId":76428219,"sourceType":"kernelVersion"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":15188.521401,"end_time":"2025-11-18T21:29:34.608335","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-18T17:16:26.086934","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4dd0cbc4","cell_type":"code","source":"!pip install scikit-learn==1.5.0\n!pip install optuna","metadata":{"execution":{"iopub.status.busy":"2025-11-19T20:15:26.956234Z","iopub.execute_input":"2025-11-19T20:15:26.956454Z","iopub.status.idle":"2025-11-19T20:15:38.579837Z","shell.execute_reply.started":"2025-11-19T20:15:26.956436Z","shell.execute_reply":"2025-11-19T20:15:38.579103Z"},"papermill":{"duration":11.217763,"end_time":"2025-11-18T17:16:41.141407","exception":false,"start_time":"2025-11-18T17:16:29.923644","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Collecting scikit-learn==1.5.0\n  Downloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.0) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.0) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.0) (1.5.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.0) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.0) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.5.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.5.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.5->scikit-learn==1.5.0) (2024.2.0)\nDownloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.5.0\nRequirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.5.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.17.1)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.10.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"id":"3ddb763a","cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import transforms as T\nimport torch.utils.data as data_utils\nfrom torch.utils.data import TensorDataset, random_split, DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nimport optuna\nimport optuna.visualization as vis\nimport cupy as cp\nfrom cuml.manifold import UMAP as cumlUMAP\nfrom ipywidgets import interact, FloatSlider","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-11-19T20:15:38.581767Z","iopub.execute_input":"2025-11-19T20:15:38.581998Z","iopub.status.idle":"2025-11-19T20:15:55.846198Z","shell.execute_reply.started":"2025-11-19T20:15:38.581975Z","shell.execute_reply":"2025-11-19T20:15:55.845335Z"},"papermill":{"duration":20.608802,"end_time":"2025-11-18T17:17:01.756199","exception":false,"start_time":"2025-11-18T17:16:41.147397","status":"completed"},"tags":[],"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":2},{"id":"4c884ebe","cell_type":"markdown","source":"crear device para pytorch","metadata":{"papermill":{"duration":0.004976,"end_time":"2025-11-18T17:17:01.766719","exception":false,"start_time":"2025-11-18T17:17:01.761743","status":"completed"},"tags":[]}},{"id":"cd9aaf47","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T20:15:55.847051Z","iopub.execute_input":"2025-11-19T20:15:55.848092Z","iopub.status.idle":"2025-11-19T20:15:55.854778Z","shell.execute_reply.started":"2025-11-19T20:15:55.848069Z","shell.execute_reply":"2025-11-19T20:15:55.853993Z"},"papermill":{"duration":0.013436,"end_time":"2025-11-18T17:17:01.785130","exception":false,"start_time":"2025-11-18T17:17:01.771694","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"1c89a76d","cell_type":"markdown","source":"Descargar el dataset ","metadata":{"papermill":{"duration":0.004859,"end_time":"2025-11-18T17:17:01.794828","exception":false,"start_time":"2025-11-18T17:17:01.789969","status":"completed"},"tags":[]}},{"id":"13e72bd8","cell_type":"code","source":"data_set = np.load('/kaggle/input/kdm-database-spiners/data.npy.npz')\nprint(data_set.files)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T20:15:55.855788Z","iopub.execute_input":"2025-11-19T20:15:55.856152Z","iopub.status.idle":"2025-11-19T20:15:55.895788Z","shell.execute_reply.started":"2025-11-19T20:15:55.856133Z","shell.execute_reply":"2025-11-19T20:15:55.895112Z"},"papermill":{"duration":0.033855,"end_time":"2025-11-18T17:17:01.833478","exception":false,"start_time":"2025-11-18T17:17:01.799623","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"['Nest', 'L', 'rd', 'So', 'T', 'Jex', 'Jex2', 'Jex3', 'Jex4', 'Kan1', 'KanS', 'Hex', 'kd', 'KDM', 'MS']\n","output_type":"stream"}],"execution_count":4},{"id":"ff7e4a79","cell_type":"markdown","source":"En \"data\" se cargan las imagenes de las configuraciones de los espines, se reorganiza para que quede de la forma (N, C, H, W). Se redimensiona de 39x39 a 40x40 para que el cambio de dimensionalidad sea simetrico en el encoder y el decoder","metadata":{"papermill":{"duration":0.004846,"end_time":"2025-11-18T17:17:01.843431","exception":false,"start_time":"2025-11-18T17:17:01.838585","status":"completed"},"tags":[]}},{"id":"005f944e","cell_type":"code","source":"data = data_set['MS']\ndata.shape\ndata = torch.from_numpy(data).permute(0, 3, 1, 2).float()\ndata = F.interpolate(data, size=(40, 40), mode='bilinear')\ndata = data / data.max() #normalizar, queda [-1,1]\ndata = (data + 1) / 2 #mover rango [0,1]\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2025-11-19T20:15:55.896436Z","iopub.execute_input":"2025-11-19T20:15:55.896696Z","iopub.status.idle":"2025-11-19T20:16:15.593130Z","shell.execute_reply.started":"2025-11-19T20:15:55.896671Z","shell.execute_reply":"2025-11-19T20:16:15.592539Z"},"papermill":{"duration":20.004336,"end_time":"2025-11-18T17:17:21.852570","exception":false,"start_time":"2025-11-18T17:17:01.848234","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"torch.Size([164212, 1, 40, 40])"},"metadata":{}}],"execution_count":5},{"id":"6e272ff6","cell_type":"markdown","source":"Como este es un cvae, \"y\" va a ser el vector con los parámetros que van a condicionar el modelo","metadata":{"papermill":{"duration":0.005485,"end_time":"2025-11-18T17:17:21.863458","exception":false,"start_time":"2025-11-18T17:17:21.857973","status":"completed"},"tags":[]}},{"id":"51d0dae4","cell_type":"code","source":"kdm = data_set['KDM']\nt = data_set['T']\ny = np.column_stack((kdm, t))\ny = torch.from_numpy(y).float()\ny.shape","metadata":{"execution":{"iopub.status.busy":"2025-11-19T20:16:15.593903Z","iopub.execute_input":"2025-11-19T20:16:15.594123Z","iopub.status.idle":"2025-11-19T20:16:15.646986Z","shell.execute_reply.started":"2025-11-19T20:16:15.594106Z","shell.execute_reply":"2025-11-19T20:16:15.646227Z"},"papermill":{"duration":0.055175,"end_time":"2025-11-18T17:17:21.923809","exception":false,"start_time":"2025-11-18T17:17:21.868634","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"torch.Size([164212, 2])"},"metadata":{}}],"execution_count":6},{"id":"10622a84","cell_type":"code","source":"full_dataset = TensorDataset(data, y)\n\nval_size = int(len(full_dataset) * 0.2)\ntrain_size = len(full_dataset) - val_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2025-11-19T20:16:15.648993Z","iopub.execute_input":"2025-11-19T20:16:15.649217Z","iopub.status.idle":"2025-11-19T20:16:15.687284Z","shell.execute_reply.started":"2025-11-19T20:16:15.649200Z","shell.execute_reply":"2025-11-19T20:16:15.686542Z"},"papermill":{"duration":0.031506,"end_time":"2025-11-18T17:17:21.962822","exception":false,"start_time":"2025-11-18T17:17:21.931316","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"id":"d2aded07","cell_type":"code","source":"train_loader = data_utils.DataLoader(\n    train_dataset, \n    batch_size=128, \n    shuffle=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=128, \n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T20:16:15.688109Z","iopub.execute_input":"2025-11-19T20:16:15.688359Z","iopub.status.idle":"2025-11-19T20:16:15.701417Z","shell.execute_reply.started":"2025-11-19T20:16:15.688340Z","shell.execute_reply":"2025-11-19T20:16:15.700657Z"},"papermill":{"duration":0.011484,"end_time":"2025-11-18T17:17:21.979989","exception":false,"start_time":"2025-11-18T17:17:21.968505","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"030cf796","cell_type":"markdown","source":"#### La arquitectura de este CVAE cuenta:\nEste es la primera versión del CVAE (concatenación + prior condicionado). \nEn este modelo, el VAE se condicionó de la siguiente manera:\n- Se pasaron los parámetros (kdm y t) por redes densas y se concatenaron a la salida flatten del encoder, resultando en una distribución $q(x|y)$\n- Se condicionó el prior, es decir, se pasó de $p(z)$ a $p(z|y)$\n  \nDonde $y$ es el vector que contiene a los parámetros kdm y t.\n\nAsí, de la distribución marginal aproximada por el encoder $q(x|y)$ resulta $\\mu_q$ y $\\log{\\sigma_q}$\n\nY de la distribución prior $p(z|y)$ resulta $\\mu_p$ y $\\log{\\sigma_p}$\n\nPara el encoder: se deja la función build_encoder para que durante la optimización pruebe diferentes configuraciones de capas, un flaten despues del ciclo para aplanar los datos y una densa para hallar $\\mu$ y $\\sigma$\n\nPara el dencoder: una densa para aumentar la dimension de z, una unflatten para pasar de un vector a un tensor y en base al ciclo propuesto en el encoder se establece el número de capas convtranspose que requiere el decoder\n\nAdemás, se define una función infer_star_dim para calcular el tamaño que tiene el tensor al final del encoder. Lo que se hace es pasar un tensor de ceros con el mismo tamaño de la imagen original a través del encoder, así, se guarda las dimensiones de la ultima capa conv para cuando se necesite hacer unflatten","metadata":{"papermill":{"duration":0.004992,"end_time":"2025-11-18T17:17:21.990325","exception":false,"start_time":"2025-11-18T17:17:21.985333","status":"completed"},"tags":[]}},{"id":"5b635050","cell_type":"code","source":"class CVAE(nn.Module):\n    def __init__(self, z_dim, layers_config, device, cond_dim=2):\n        super(CVAE, self).__init__()\n        self.z_dim = z_dim\n        self.layers_config = layers_config\n        self.kernel_size = 4\n        self.stride = 2\n        self.padding = 1\n        self.cond_dim = cond_dim\n        # mover todo a gpu\n        self.device = device  \n\n        self.cond = nn.Sequential(\n            nn.Linear(self.cond_dim, 64),\n            nn.LeakyReLU(0.2),\n            nn.Linear(64, 128),\n            nn.LeakyReLU(0.2)\n        ).to(self.device)\n        \n        self.cond_dim_process = 128\n\n        self.encoder = self._build_encoder(layers_config).to(self.device)\n        self.flat_dim, self.h_start, self.w_start = self._infer_start_dim()\n        \n        self.fc_mu_q = nn.Linear(self.flat_dim + self.cond_dim_process, z_dim).to(self.device)\n        self.fc_logvar_q = nn.Linear(self.flat_dim + self.cond_dim_process, z_dim).to(self.device)\n        self.decoder = self._build_decoder().to(self.device)\n\n        # condicionamiento en el prior\n        self.fc_mu_p = nn.Linear(self.cond_dim_process, z_dim).to(self.device)\n        self.fc_logvar_p = nn.Linear(self.cond_dim_process, z_dim).to(self.device)\n        \n    # crea el encoder en base a las configuraciones\n    def _build_encoder(self, layers_config):\n        layers = []\n        in_ch = 1\n        for (n_filters, use_bn) in layers_config:\n            layers.append(nn.Conv2d(in_ch, n_filters, kernel_size=3, stride=2, padding=1))\n            if use_bn:\n                layers.append(nn.BatchNorm2d(n_filters))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            in_ch = n_filters\n        layers.append(nn.Flatten())\n        encoder = nn.Sequential(*layers)\n        return encoder\n\n    # se guardan dimensiones de la ultima capa\n    def _infer_start_dim(self):\n        # tensor de ceros con el tamaño de la imagen para pasarlo por el encoder\n        x = torch.zeros(1, 1, 40, 40).to(self.device)\n        \n        with torch.no_grad():\n            # encoder temporal sin flatten para medir dimensiones espaciales\n            temp_encoder = nn.Sequential(*list(self.encoder.children())[:-1]) \n            temp_encoder.eval()            \n            current_layer = x\n\n            \n            for layer in temp_encoder:\n                current_layer = layer(current_layer)\n\n            out = current_layer\n        \n        flat_dim = out.shape[1] * out.shape[2] * out.shape[3]\n        h_start, w_start = out.shape[2], out.shape[3] \n        \n        return flat_dim, h_start, w_start\n\n    # crea el decoder también en base a las configuraciones de capas\n    def _build_decoder(self):\n        layers = []\n        layers.append(nn.Linear(self.z_dim + self.cond_dim_process, self.flat_dim))\n        # se pasa deun vector plano a un tensor con las dimensiones de la ultima capa convolucional del encoder\n        layers.append(nn.Unflatten(1, (self.layers_config[-1][0], self.h_start, self.w_start)))\n        layers.append(nn.LeakyReLU(0.2, inplace=True))\n        \n        # se invierte el vector de las configuraciones\n        reversed_config = list(reversed(self.layers_config))\n        \n        N_layers = len(reversed_config) # Total de capas transpuestas necesarias\n        \n        # la primera entrada (input chanel) es la última del encoder\n        in_ch = reversed_config[0][0] \n        for i in range(N_layers): \n            \n            # atualización de los canales\n            is_final_layer = (i == N_layers - 1)\n            \n            # si no es la capa final, el out_ch es el filtro de la siguiente capa en la config inversa\n            out_ch = 1 if is_final_layer else reversed_config[i+1][0] \n            \n            # la configuración de BN se toma de la capa a la que se está transponiendo (el out_ch)\n            use_bn = reversed_config[i+1][1] if not is_final_layer else False\n            \n            # se construyen las capas conv\n            layers.append(nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1))\n            in_ch = out_ch\n            \n            # Aplicar BN y LeakyReLU, excepto en la capa de salida final\n            if not is_final_layer:\n                if use_bn:\n                    layers.append(nn.BatchNorm2d(out_ch))\n                layers.append(nn.LeakyReLU(0.2, inplace=True))\n            else:\n                layers.append(nn.Sigmoid())\n                \n        decoder = nn.Sequential(*layers)\n        return decoder\n    \n    def encode(self, x, y):\n        h = self.encoder(x)\n        y_process = self.cond(y)\n        #concatenacion\n        combined = torch.cat([h, y_process], dim=1)\n        mu_q = self.fc_mu_q(combined)\n        logvar_q = self.fc_logvar_q(combined)\n        return mu_q, logvar_q\n\n    # Calcula el prior condicionado\n    def get_prior(self, y):\n        y_process = self.cond(y)\n        mu_p = self.fc_mu_p(y_process)\n        logvar_p = self.fc_logvar_p(y_process)\n        return mu_p, logvar_p\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        z = mu + eps*std\n        return z\n\n    def decode(self, z, y):\n        y_process = self.cond(y)\n        combined = torch.cat([z, y_process], dim=1)\n        return self.decoder(combined)\n\n    def forward(self, x, y):\n        mu_q, logvar_q = self.encode(x, y)\n        z = self.reparameterize(mu_q, logvar_q)\n        x_hat = self.decode(z, y)\n        mu_p, logvar_p = self.get_prior(y)\n        return x_hat, mu_q, logvar_q, mu_p, logvar_p\n\n    def get_intermediate_features(self, x):\n        features = {}\n        h = x\n        conv_blocks = list(self.encoder.children())\n        \n        # Layer 1\n        h = conv_blocks[0](h)\n        # Aplanar de (B, C, H, W) a (B, C*H*W)\n        features['L1'] = h.flatten(start_dim=1) \n        \n        # Layer 2\n        h = conv_blocks[1](h)\n        features['L2'] = h.flatten(start_dim=1)\n    \n        # Layer 3\n        h = conv_blocks[2](h)\n        features['L3'] = h.flatten(start_dim=1)\n        \n        return features","metadata":{"execution":{"iopub.status.busy":"2025-11-19T20:16:15.702274Z","iopub.execute_input":"2025-11-19T20:16:15.702558Z","iopub.status.idle":"2025-11-19T20:16:15.722888Z","shell.execute_reply.started":"2025-11-19T20:16:15.702535Z","shell.execute_reply":"2025-11-19T20:16:15.722224Z"},"papermill":{"duration":0.026077,"end_time":"2025-11-18T17:17:22.021530","exception":false,"start_time":"2025-11-18T17:17:21.995453","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"cc52acb7-84de-4139-a627-2e5ca3cad657","cell_type":"markdown","source":"Se cargan los pesos del modelo previamente entrenado y los mejores parámetros encontrados","metadata":{}},{"id":"a9eb2b5e-4985-4cce-bae6-3250fedc583f","cell_type":"code","source":"## params \nbest_params = {'lr': 0.0011785331104065553, \n               'z_dim': 64, \n               'beta': 0.1013322948202451, \n               'batch_size': 64, \n               'base_filters': 64, \n               'growth': 1.476083655965836, \n               'use_bn': False}\n\nz_dim = best_params['z_dim'] \nbeta = best_params['beta']\nnum_layers = 3\nbase_filters = best_params['base_filters']\ngrowth = best_params['growth']\nuse_bn = best_params['use_bn']\n\nlayers_config = []\n\nfor i in range(num_layers):\n        filters = int(base_filters * (growth ** i))\n        layers_config.append((filters, use_bn))\n\nmodel = CVAE(z_dim=z_dim, layers_config=layers_config, device=device, cond_dim=2)\npesos = \"/kaggle/input/pesos-cvae-emb-co/vae_spines_pesos_final.pth\"\nstate_dict = torch.load(pesos, map_location=device)\nmodel.load_state_dict(state_dict)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:16:15.723855Z","iopub.execute_input":"2025-11-19T20:16:15.724132Z","iopub.status.idle":"2025-11-19T20:16:16.573916Z","shell.execute_reply.started":"2025-11-19T20:16:15.724109Z","shell.execute_reply":"2025-11-19T20:16:16.573037Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"CVAE(\n  (cond): Sequential(\n    (0): Linear(in_features=2, out_features=64, bias=True)\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Linear(in_features=64, out_features=128, bias=True)\n    (3): LeakyReLU(negative_slope=0.2)\n  )\n  (encoder): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(64, 94, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n    (4): Conv2d(94, 139, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n    (6): Flatten(start_dim=1, end_dim=-1)\n  )\n  (fc_mu_q): Linear(in_features=3603, out_features=64, bias=True)\n  (fc_logvar_q): Linear(in_features=3603, out_features=64, bias=True)\n  (decoder): Sequential(\n    (0): Linear(in_features=192, out_features=3475, bias=True)\n    (1): Unflatten(dim=1, unflattened_size=(139, 5, 5))\n    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n    (3): ConvTranspose2d(139, 94, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): ConvTranspose2d(94, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n    (7): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (8): Sigmoid()\n  )\n  (fc_mu_p): Linear(in_features=128, out_features=64, bias=True)\n  (fc_logvar_p): Linear(in_features=128, out_features=64, bias=True)\n)"},"metadata":{}}],"execution_count":10},{"id":"463cf155-13d6-4d8b-830d-c090b66ea81f","cell_type":"code","source":"def generar_espin(kdm_valor, t_valor):\n    model.eval()\n    y_input = torch.tensor([[kdm_valor, t_valor]], dtype=torch.float32).to(device)\n    \n    with torch.no_grad():\n        mu_p, logvar_p = model.get_prior(y_input)\n        z_sample = model.reparameterize(mu_p, logvar_p)\n        imagen_generada = model.decode(z_sample, y_input) \n    imagen_numpy = imagen_generada.cpu().squeeze().numpy()\n    plt.figure(figsize=(5, 5))\n    plt.imshow(imagen_numpy, cmap='jet') # 'jet' parece ser tu mapa de color\n    plt.colorbar(label=\"orientación\")\n    plt.title(f\"Estimación\\nKDM={kdm_valor} | T={t_valor}\")\n    plt.axis('off')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:24:01.780895Z","iopub.execute_input":"2025-11-19T20:24:01.781644Z","iopub.status.idle":"2025-11-19T20:24:01.786841Z","shell.execute_reply.started":"2025-11-19T20:24:01.781619Z","shell.execute_reply":"2025-11-19T20:24:01.786129Z"}},"outputs":[],"execution_count":35},{"id":"51ae6c12-c30d-446a-a12c-139960fc1a49","cell_type":"code","source":"interact(generar_espin, \n         kdm_valor=FloatSlider(min=0.01, max=1.2, step=0.1, value=0.0, description='KDM'),\n         t_valor=FloatSlider(min=0.01, max=20, step=0.1, value=1.0, description='T'));","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:25:04.448503Z","iopub.execute_input":"2025-11-19T20:25:04.448816Z","iopub.status.idle":"2025-11-19T20:25:04.598569Z","shell.execute_reply.started":"2025-11-19T20:25:04.448792Z","shell.execute_reply":"2025-11-19T20:25:04.597990Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"interactive(children=(FloatSlider(value=0.01, description='KDM', max=1.2, min=0.01), FloatSlider(value=1.0, de…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"947fe97fc25b40c38f7a8a24c11feaff"}},"metadata":{}}],"execution_count":36}]}